{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c1de86",
   "metadata": {},
   "source": [
    "## MNIST Digits Classification with Machine Learning:\n",
    "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes.\n",
    "\n",
    "Our goal would be to build a neural network with 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe012e4",
   "metadata": {},
   "source": [
    "### Import the necessary Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33be7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfdt  \n",
    "#tensorflow's data provider for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cec985",
   "metadata": {},
   "source": [
    "### Load the dataset in the 2-tuple structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e018b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfdt.load(name='MNIST',with_info=True,as_supervised = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b3c0b2",
   "metadata": {},
   "source": [
    "### Extract the training and testing dataset and create the validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4c6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once we have loaded the dataset, we can easily extract the training and testing dataset with the built references\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "\n",
    "\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "# .num_examples -> It contains the number of images in the test data set.\n",
    "# mnist_info.splits['test'].num_examples -> returns 10,000, which is the number of samples (images) in the test split of the mnist data set.\n",
    "\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d5c6e",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575cc25f",
   "metadata": {},
   "source": [
    "### Scaling the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f276b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "    return image, label\n",
    "\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457e4d8",
   "metadata": {},
   "source": [
    "### Shuffling and batching the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87dc0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531f39aa",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429e4ca",
   "metadata": {},
   "source": [
    "### Outlining the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079a38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 100\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')   \n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe108a",
   "metadata": {},
   "source": [
    "### Optimizing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f2bce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77455933",
   "metadata": {},
   "source": [
    "### Training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ee11e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 3s - loss: 0.3452 - accuracy: 0.9007 - val_loss: 0.1767 - val_accuracy: 0.9482 - 3s/epoch - 5ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 2s - loss: 0.1398 - accuracy: 0.9585 - val_loss: 0.1224 - val_accuracy: 0.9647 - 2s/epoch - 3ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 2s - loss: 0.1017 - accuracy: 0.9690 - val_loss: 0.1134 - val_accuracy: 0.9677 - 2s/epoch - 3ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 2s - loss: 0.0794 - accuracy: 0.9755 - val_loss: 0.0932 - val_accuracy: 0.9717 - 2s/epoch - 3ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 1s - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0737 - val_accuracy: 0.9762 - 1s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2058eeb98e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5  # do it 6 and see different\n",
    "\n",
    "model.fit(train_data, epochs = NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7852c439",
   "metadata": {},
   "source": [
    "### Evaluating the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f18475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0847 - accuracy: 0.9749\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ef3d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08. Test accuracy: 97.49%\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8fa868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
